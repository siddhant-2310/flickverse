{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# Get the API key from environment variables\n",
    "api_key = os.getenv(\"REACT_APP_TMDB_API_KEY\")\n",
    "\n",
    "def fetch_with_retry(url, retries=3, delay=5):\n",
    "    \"\"\"Fetches a URL with a simple retry mechanism.\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an exception for bad status codes\n",
    "            return response\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}. Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "    raise Exception(f\"Failed to fetch {url} after {retries} retries.\")\n",
    "\n",
    "def fetch_movie_data():\n",
    "    \"\"\"Fetches movie data from the TMDB API.\"\"\"\n",
    "    print(\"Fetching movie data...\")\n",
    "    # Using the \"Top Rated\" endpoint to get a good base of movies\n",
    "    url = f'https://api.themoviedb.org/3/movie/top_rated?api_key={api_key}&language=en-US&page=1'\n",
    "    response = fetch_with_retry(url)\n",
    "    \n",
    "    data = response.json()['results']\n",
    "    \n",
    "    # Fetch more pages to get a larger dataset (approx. 5000 movies)\n",
    "    print(\"Fetching pages 2 to 250...\")\n",
    "    for i in range(2, 251): # 250 pages * 20 movies/page = 5000 movies\n",
    "        print(f\"Fetching page {i}...\")\n",
    "        url = f'https://api.themoviedb.org/3/movie/top_rated?api_key={api_key}&language=en-US&page={i}'\n",
    "        try:\n",
    "            response = fetch_with_retry(url)\n",
    "            data.extend(response.json()['results'])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}. Skipping page {i}.\")\n",
    "        time.sleep(0.1) # Short delay to be polite to the API\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Fetched {len(df)} movies.\")\n",
    "    return df\n",
    "\n",
    "def fetch_credits_and_keywords(movie_id):\n",
    "    \"\"\"Fetches credits (cast, crew) and keywords for a single movie.\"\"\"\n",
    "    # Fetch credits\n",
    "    credits_url = f'https://api.themoviedb.org/3/movie/{movie_id}/credits?api_key={api_key}'\n",
    "    # Fetch keywords\n",
    "    keywords_url = f'https://api.themoviedb.org/3/movie/{movie_id}/keywords?api_key={api_key}'\n",
    "\n",
    "    try:\n",
    "        credits_response = fetch_with_retry(credits_url)\n",
    "        keywords_response = fetch_with_retry(keywords_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not fetch details for movie_id {movie_id}. {e}\")\n",
    "        return [], [], []\n",
    "\n",
    "    # Extract director from crew\n",
    "    crew = credits_response.json().get('crew', [])\n",
    "    director = [i['name'] for i in crew if i['job'] == 'Director']\n",
    "    \n",
    "    # Extract top 3 cast members\n",
    "    cast = [i['name'] for i in credits_response.json().get('cast', [])[:3]]\n",
    "    \n",
    "    # Extract all keywords\n",
    "    keywords = [i['name'] for i in keywords_response.json().get('keywords', [])]\n",
    "    \n",
    "    return director, cast, keywords\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"Processes the movie data to create a 'tags' column for vectorization.\"\"\"\n",
    "    print(\"Processing data...\")\n",
    "    # We only need a few columns\n",
    "    df = df[['id', 'title', 'overview', 'genre_ids']].copy()\n",
    "    \n",
    "    # For simplicity, we'll map genre_ids to genre names manually from TMDB's genre list\n",
    "    genre_map = {28:'Action',12:'Adventure',16:'Animation',35:'Comedy',80:'Crime',99:'Documentary',18:'Drama',10751:'Family',14:'Fantasy',36:'History',27:'Horror',10402:'Music',9648:'Mystery',10749:'Romance',878:'Science Fiction',10770:'TV Movie',53:'Thriller',10752:'War',37:'Western'}\n",
    "    df['genres'] = df['genre_ids'].apply(lambda ids: [genre_map.get(i, '') for i in ids])\n",
    "\n",
    "    # Fetch credits and keywords for each movie with progress updates\n",
    "    directors = []\n",
    "    casts = []\n",
    "    keywords_list = []\n",
    "    total_movies = len(df)\n",
    "    print(f\"Fetching details for {total_movies} movies...\")\n",
    "    for index, row in df.iterrows():\n",
    "        director, cast, keywords = fetch_credits_and_keywords(row['id'])\n",
    "        directors.append(director)\n",
    "        casts.append(cast)\n",
    "        keywords_list.append(keywords)\n",
    "        if (index + 1) % 500 == 0:\n",
    "            print(f\"  Processed {index + 1} / {total_movies} movies...\")\n",
    "\n",
    "    df['director'] = directors\n",
    "    df['cast'] = casts\n",
    "    df['keywords'] = keywords_list\n",
    "\n",
    "    # Clean and combine features into a single 'tags' string\n",
    "    df['overview'] = df['overview'].fillna('').apply(lambda x: x.split())\n",
    "    df['genres'] = df['genres'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "    df['director'] = df['director'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "    df['cast'] = df['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "    df['keywords'] = df['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "    \n",
    "    df['tags'] = df['overview'] + df['genres'] + df['keywords'] + df['cast'] + df['director']\n",
    "    df['tags'] = df['tags'].apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    processed_df = df[['id', 'title', 'tags']].copy()\n",
    "    print(\"Data processing complete.\")\n",
    "    return processed_df\n",
    "\n",
    "def create_model(df):\n",
    "    \"\"\"Creates the TF-IDF model and cosine similarity matrix.\"\"\"\n",
    "    print(\"Creating model...\")\n",
    "    tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    vectors = tfidf.fit_transform(df['tags']).toarray()\n",
    "    \n",
    "    similarity = cosine_similarity(vectors)\n",
    "    print(\"Model creation complete.\")\n",
    "    return similarity\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the data fetching, processing, and model creation.\"\"\"\n",
    "    try:\n",
    "        movie_df = fetch_movie_data()\n",
    "        processed_df = process_data(movie_df)\n",
    "        similarity_matrix = create_model(processed_df)\n",
    "        \n",
    "        # Save the processed dataframe and similarity matrix\n",
    "        pickle.dump(processed_df.to_dict(), open('movies.pkl', 'wb'))\n",
    "        pickle.dump(similarity_matrix, open('similarity.pkl', 'wb'))\n",
    "        \n",
    "        print(\"\\nSuccessfully created and saved 'movies.pkl' and 'similarity.pkl'\")\n",
    "        print(\"You can now run the Flask server using 'python app.py'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Please ensure your TMDB API key is correct in the .env file.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}